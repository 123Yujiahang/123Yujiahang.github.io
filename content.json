{"meta":{"title":"123Yujiahang's Wiki","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"Tags","date":"2022-05-16T08:01:15.999Z","updated":"2022-05-16T06:17:34.983Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"About","date":"2022-05-16T08:00:57.292Z","updated":"2022-05-16T06:17:34.980Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"Categories","date":"2022-05-16T08:01:03.308Z","updated":"2022-05-16T06:17:34.980Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"一、Spark基础配置","date":"2022-05-16T11:02:02.884Z","updated":"2022-05-16T10:52:54.868Z","comments":true,"path":"2022/05/16/一、Spark基础配置/","link":"","permalink":"http://example.com/2022/05/16/%E4%B8%80%E3%80%81Spark%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/","excerpt":"","text":"一、安装配置 jdk 编译环境软件安装目录 1mkdir -p /export/server JDK 1.8安装 上传 jdk-8u241-linux-x64.tar.gz到&#x2F;export&#x2F;server&#x2F;目录下 并解压文件 1tar -zxvf jdk-8u241-linux-x64.tar.gz 配置环境变量 12345vim /etc/profileexport JAVA_HOME=/export/server/jdk1.8.0_241export PATH=$PATH:$JAVA_HOME/binexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 重新加载环境变量文件 1source /etc/profile 查看 java 版本号 1java -version 12345结果显示：[root@master jdk1.8.0_241]# java -versionjava version &quot;1.8.0_241&quot;Java(TM) SE Runtime Environment (build 1.8.0_241-b07)Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode) master 节点将 java 传输到 slave1 和 slave2 12scp -r /export/server/jdk1.8.0_241/ root@slave1:/export/server/scp -r /export/server/jdk1.8.0_241/ root@slave2:/export/server/ 配置 slave1 和 slave2 的 jdk 环境变量（注：和上方 master 的配置方法一样） 在 master slave1 和slave2 创建软连接 123cd /export/serverln -s jdk1.8.0_241/ jdk 重新加载环境变量文件 1source /etc/profile 二、zookeeper安装配置 配置主机名和IP的映射关系，修改 &#x2F;etc&#x2F;hosts 文件，添加 master.root slave1.root slave2.root 123456789vim /etc/hosts#结果显示127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.88.135 master master.root192.168.88.136 slave1 slave1.root192.168.88.137 slave2 slave2.root zookeeper安装 上传 zookeeper-3.4.10.tar.gz到&#x2F;export&#x2F;server&#x2F;目录下 并解压文件 123cd /export/server/tar -zxvf zookeeper-3.4.10.tar.gz 在 &#x2F;export&#x2F;server 目录下创建软连接 123cd /export/serverln -s zookeeper-3.4.10/ zookeeper 进入 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;conf&#x2F; 将 zoo_sample.cfg 文件复制为新文件 zoo.cfg 123cd /export/server/zookeeper/conf/ cp zoo_sample.cfg zoo.cfg 接上步给 zoo.cfg 添加内容 1234567891011121314#Zookeeper的数据存放目录dataDir=/export/server/zookeeper/zkdatas# 保留多少个快照autopurge.snapRetainCount=3# 日志多少小时清理一次autopurge.purgeInterval=1# 集群中服务器地址server.1=master:2888:3888server.2=slave1:2888:3888server.3=slave2:2888:3888 进入 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas 目录在此目录下创建 myid 文件，将 1 写入进去 12345cd /export/server/zookeeper/zkdatatouch myidecho &#x27;1&#x27; &gt; myid 将 master 节点中 &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.10 路径下内容推送给slave1 和 slave2 123scp -r /export/server/zookeeper-3.4.10/ slave1:$PWDscp -r /export/server/zookeeper-3.4.10/ slave2:$PWD 推送成功后，分别在 slave1 和 slave2 上创建软连接 1ln -s zookeeper-3.4.10/ zookeeper 接上步推送完成后将 slave1 和 slave2 的 &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F; 文件夹下的 myid 中的内容分别改为 2 和 3 123456789cd /export/server/zookeeper/zkdatas/结果显示：[root@slave1 zkdatas]# vim myid [root@slave1 zkdatas]# more myid 2[root@slave2 zkdatas]# vim myid [root@slave2 zkdatas]# more myid 3 配置zookeeper的环境变量（注：三台主机都需要配置） 12345vim /etc/profile# zookeeper 环境变量export ZOOKEEPER_HOME=/export/server/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/bin 重新加载环境变量文件 1source /etc/profile 进入 &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.10&#x2F;bin 目录下启动 zkServer.sh 脚本 （注：三台都需要做） 123cd /export/server/zookeeper-3.4.10/bin zkServer.sh start 12345结果显示：[root@master bin]# ./zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfgStarting zookeeper ... STARTED 查看 zookeeper 的状态 1zkServer.sh status 123456789101112131415结果显示：[root@master server]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: follower[root@slave1 server]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: follower[root@slave2 conf]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /export/server/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: leader 1jps 123456789101112结果显示：[root@master server]# jps125348 QuorumPeerMain16311 Jps[root@slave1 server]# jps126688 QuorumPeerMain17685 Jps[root@slave2 conf]# jps126733 QuorumPeerMain17727 Jps 脚本一键启动 1234567891011121314151617181920212223242526272829303132333435vim zkServer.sh#!/bin/bashif [ $# -eq 0 ] ;then echo &quot;please input param:start stop&quot;elseif [ $1 = start ] ;then echo &quot;$&#123;1&#125;ing master&quot; ssh master &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh start&quot; for i in &#123;1..2&#125; do echo &quot;$&#123;1&#125;ping slave$&#123;i&#125;&quot; ssh slave$&#123;i&#125; &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh start&quot; donefiif [ $1 = stop ];then echo &quot;$&#123;1&#125;ping master &quot; ssh master &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh stop&quot; for i in &#123;1..2&#125; do echo &quot;$&#123;1&#125;ping slave$&#123;i&#125;&quot; ssh slave$&#123;i&#125; &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh stop&quot; donefiif [ $1 = status ];then echo &quot;$&#123;1&#125;ing master&quot; ssh master &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh status&quot; for i in &#123;1..2&#125; do echo &quot;$&#123;1&#125;ping slave$&#123;i&#125;&quot; ssh slave$&#123;i&#125; &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh status&quot; donefifi 12# 将文件放在 /bin 目录下chmod +x zkServer-all.sh &amp;&amp; zkServer-all.sh 三、Hadoop 安装配置 把 hadoop-3.3.0-Centos7-64-with-snappy.tar.gz 上传到 &#x2F;export&#x2F;server 并解压文件 1tar -zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz 修改配置文件(进入路径 &#x2F;export&#x2F;server&#x2F;hadoop-3.3.0&#x2F;etc&#x2F;hadoop) 1cd /export/server/hadoop-3.3.0/etc/hadoop hadoop-env.sh 12345678#文件最后添加export JAVA_HOME=/export/server/jdk1.8.0_241export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root core-site.xml 12345678910111213141516171819202122232425262728293031323334&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:8020&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置Hadoop本地保存数据路径 --&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置HDFS web UI用户身份 --&gt;&lt;property&gt; &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt; &lt;value&gt;root&lt;/value&gt;&lt;/property&gt;&lt;!-- 整合hive 用户代理设置 --&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt;&lt;/property&gt;&lt;!-- 文件系统垃圾桶保存时间 --&gt;&lt;property&gt; &lt;name&gt;fs.trash.interval&lt;/name&gt; &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt; hdfs-site.xml 12345&lt;!-- 设置SNN进程运行机器位置信息 --&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;slave1:9868&lt;/value&gt;&lt;/property&gt; mapred-site.xml 1234567891011121314151617181920212223242526272829303132&lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;!-- MR程序历史服务地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;master:10020&lt;/value&gt;&lt;/property&gt; &lt;!-- MR程序历史服务器web端地址 --&gt;&lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:19888&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.map.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapreduce.reduce.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;&lt;/property&gt; yarn-site.xml 12345678910111213141516171819202122232425262728293031323334353637383940&lt;!-- 设置YARN集群主角色运行机器位置 --&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;!-- 是否将对容器实施物理内存限制 --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;!-- 开启日志聚集 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 设置yarn历史服务器地址 --&gt;&lt;property&gt; &lt;name&gt;yarn.log.server.url&lt;/name&gt; &lt;value&gt;http://master:19888/jobhistory/logs&lt;/value&gt;&lt;/property&gt;&lt;!-- 历史日志保存的时间 7天 --&gt;&lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;604800&lt;/value&gt;&lt;/property&gt; workers 123masterslave1slave2 分发同步hadoop安装包 1234cd /export/serverscp -r hadoop-3.3.0 root@slave1:$PWDscp -r hadoop-3.3.0 root@slave2:$PWD 将hadoop添加到环境变量 1234vim /etc/profileexport HADOOP_HOME=/export/server/hadoop-3.3.0export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 重新加载环境变量文件 1source /etc/profile Hadoop集群启动 格式化namenode（只有首次启动需要格式化） 1hdfs namenode -format 脚本一键启动 12345678910111213[root@master ~]# start-dfs.sh Starting namenodes on [master]上一次登录：五 3月 11 21:27:24 CST 2022pts/0 上Starting datanodes上一次登录：五 3月 11 21:27:32 CST 2022pts/0 上Starting secondary namenodes [slave1]上一次登录：五 3月 11 21:27:35 CST 2022pts/0 上[root@master ~]# start-yarn.sh Starting resourcemanager上一次登录：五 3月 11 21:27:41 CST 2022pts/0 上Starting nodemanagers上一次登录：五 3月 11 21:27:51 CST 2022pts/0 上 启动后 输入 jps 查看 1234567891011121314151617[root@master ~]# jps127729 NameNode127937 DataNode14105 Jps128812 NodeManager128591 ResourceManager[root@slave1 hadoop]# jps121889 NodeManager121559 SecondaryNameNode7014 Jps121369 DataNode[root@slave2 hadoop]# jps6673 Jps121543 NodeManager121098 DataNode WEB页面 HDFS集群： 1http://master:9870/ YARN集群： 1http://master:8088/ ​","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2022-05-15T12:35:33.382Z","updated":"2022-05-15T12:35:33.382Z","comments":true,"path":"2022/05/15/hello-world/","link":"","permalink":"http://example.com/2022/05/15/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[]}