<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>123Yujiahang&#39;s Wiki</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-05-17T01:32:11.943Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/05/17/Spark%20HA%20&amp;%20Yarn%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/2022/05/17/Spark%20HA%20&amp;%20Yarn%E9%85%8D%E7%BD%AE/</id>
    <published>2022-05-17T01:32:11.943Z</published>
    <updated>2022-05-17T01:32:11.943Z</updated>
    
    <content type="html"><![CDATA[<p><em><strong>*七、Spark-Standalone-HA模式*</strong></em></p><p>注：此处因为先前配置时的zookeeper版本和spark版本不太兼容，导致此模式有故障，需要重新下载配置新的版本的zookeeper。配置之前需要删除三台主机的旧版zookeeper以及对应的软连接。 </p><p>在node1节点上重新进行前面配置的zookerper操作 </p><p>\1. 上传apache-zookeeper-3.7.0-bin.tar.gz到&#x2F;export&#x2F;server&#x2F;目录下并解压文件</p><p>cd &#x2F;export&#x2F;server&#x2F;</p><p>tar -zxvf apache-zookeeper-3.7.0-bin.tar.gz</p><p>\2. 在&#x2F;export&#x2F;server&#x2F;目录下创建软连接</p><p>cd &#x2F;export&#x2F;server&#x2F;</p><p>ln -s apache-zookeeper-3.7.0-bin spark</p><p>\3. 进入&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;conf&#x2F;将zoo_sample.cfg文件复制为新文件 </p><p>zoo.cfg</p><p>\4. 接上步给zoo.cfg 添加内容 </p><p>\5. 进入&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas 目录在此目录下创建 myid 文件，将1写入进去</p><p>\6. 将node1节点中 &#x2F;export&#x2F;server&#x2F;zookeeper-3.7.0 路径下内容分发给node2和node3</p><p>\7. 分发完后，分别在node2和node3上创建软连接</p><p>\8. 将node2和node3的&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;文件夹 </p><p>下的myid中的内容分别改为2和3</p><p>配置环境变量： </p><p>因先前配置 zookeeper 时候创建过软连接且以 ’zookeeper‘ 为路径，所以不用配置环境变量，此处也是创建软连接的方便之处. </p><p>cd &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf </p><p>vim spark-env.sh</p><p>删除: SPARK_MASTER_HOST&#x3D;node1</p><p>在文末添加内容 </p><p>SPARK_DAEMON_JAVA_OPTS&#x3D;”-Dspark.deploy.recoveryMode&#x3D;ZOOKEEPER - </p><p>Dspark.deploy.zookeeper.url&#x3D;master:2181,slave1:2181,slave2:2181 - </p><p>Dspark.deploy.zookeeper.dir&#x3D;&#x2F;spark-ha” </p><p># spark.deploy.recoveryMode 指定HA模式 基于Zookeeper实现 </p><p># 指定Zookeeper的连接地址 </p><p># 指定在Zookeeper中注册临时节点的路径 </p><p>\9. 分发spark-env.sh到node2和node3上 </p><p>scp spark-env.sh node2:&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F; </p><p>scp spark-env.sh node3:&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F; </p><p>\10. 启动之前确保 Zookeeper 和 HDFS 均已经启动 </p><p>启动集群: </p><p># 在node1上 启动一个master 和全部worker</p><p>sbin&#x2F;start-all.sh</p><p># 注意, 下面命令在node2上执行</p><p>sbin&#x2F;start-master.sh</p><p># 在node2上启动一个备用的master进程</p><p>#将node1的master kill掉，查看node2的WebUI界面</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps207.tmp.jpg" alt="img"> </p><p><em><strong>*八、Spark-yarn模式*</strong></em></p><p>1、启动yarn的历史服务器，jps看进程</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps208.tmp.jpg" alt="img"> </p><p>2、在yarn上启动pyspark</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps219.tmp.jpg" alt="img"> </p><p>3、命令测试</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps21A.tmp.jpg" alt="img"> </p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps21B.tmp.jpg" alt="img"> </p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps21C.tmp.jpg" alt="img"> </p><p>4、提交任务测试</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps21D.tmp.jpg" alt="img"> </p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps21E.tmp.jpg" alt="img"> </p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps21F.tmp.jpg" alt="img"> </p><p>5、client模式测试pi</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps220.tmp.jpg" alt="img"> </p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps221.tmp.jpg" alt="img"> </p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps222.tmp.jpg" alt="img"> </p><p>6、cluster模式测试pi</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps223.tmp.jpg" alt="img"> </p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps224.tmp.jpg" alt="img"><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps225.tmp.jpg" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;*七、Spark-Standalone-HA模式*&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;注：此处因为先前配置时的zookeeper版本和spark版本不太兼容，导致此模式有故障，需要重新下载配置新的版本的zookeeper。配置之前需要删除三台</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/05/17/Spark%20local&amp;%20stand-alone%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/2022/05/17/Spark%20local&amp;%20stand-alone%E9%85%8D%E7%BD%AE/</id>
    <published>2022-05-17T01:28:25.535Z</published>
    <updated>2022-05-17T01:28:25.536Z</updated>
    
    <content type="html"><![CDATA[<p><em><strong>*五、Spark-local模式*</strong></em></p><p>\1. 上传并安装Anaconda3-2021.05-Linux-x86_64.sh文件</p><p>cd &#x2F;export&#x2F;server&#x2F;</p><p>sh Anaconda3-2021.05-Linux-x86_64.sh</p><p>\2. 过程显示： </p><p>…</p><p> # 出现内容选 yes Please answer ‘yes’ or ‘no’:’ &gt;&gt;&gt; yes</p><p>  … </p><p># 出现添加路径：&#x2F;export&#x2F;server&#x2F;anaconda3</p><p>  …</p><p>[&#x2F;root&#x2F;anaconda3]&gt;&gt;&gt;&#x2F;export&#x2F;server&#x2F;anaconda3 PREFIX&#x3D;&#x2F;export&#x2F;server&#x2F;anaconda3</p><p>  …</p><p>\3. 安装完成后，重新启动</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps618D.tmp.jpg" alt="img"> </p><p>看到base就表示安装完成了</p><p>\4. 创建虚拟环境pyspark基于python3.8</p><p>conda create -n pyspark python&#x3D;3.8</p><p>\5. 切换到虚拟环境内</p><p> conda activate pyspark</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps618E.tmp.jpg" alt="img"> </p><p>\6. 在虚拟环境内安装包</p><p>pip install pyhive pyspark jieba -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a></p><p>\7. 上传并解压spark-3.2.0-bin-hadoop3.2.tgz</p><p> cd &#x2F;export&#x2F;server</p><p> tar -zxvf spark-3.2.0-bin-hadoop3.2.tgz -C &#x2F;export&#x2F;server&#x2F;</p><p>\8. 创建软连接</p><p>ln -s &#x2F;export&#x2F;server&#x2F;spark-3.2.0-bin-hadoop3.2 &#x2F;export&#x2F;server&#x2F;spark </p><p>\9. 添加环境变量</p><p>vim &#x2F;etc&#x2F;profile</p><p>SPARK_HOME: 表示Spark安装路径在哪里</p><p>PYSPARK_PYTHON: 表示Spark想运行Python程序, 那么去哪里找python执行器</p><p>JAVA_HOME: 告知Spark Java在哪里</p><p>HADOOP_CONF_DIR: 告知Spark Hadoop的配置文件在哪里</p><p>HADOOP_HOME: 告知Spark  Hadoop安装在哪里</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps618F.tmp.jpg" alt="img"> </p><p>vim .bashrc </p><p>内容添加进去： </p><p>#JAVA_HOME </p><p>export JAVA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;jdk1.8.0_241 </p><p>#PYSPARK_PYTHON </p><p>export PYSPARK_PYTHON&#x3D;&#x2F;export&#x2F;server&#x2F;anaconda3&#x2F;envs&#x2F;pyspark&#x2F;bin&#x2F;python </p><p>\10. 重新加载环境变量</p><p>source &#x2F;etc&#x2F;profile</p><p>source ~&#x2F;.bashrc</p><p>\11. 开启spark</p><p>cd &#x2F;export&#x2F;server&#x2F;anaconda3&#x2F;ens&#x2F;pyspark&#x2F;bin&#x2F;</p><p>.&#x2F;pyspark</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps6190.tmp.jpg" alt="img"></p><p>\12. 进入WEB界面（node1:4040&#x2F;）</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps6191.tmp.jpg" alt="img"> </p><p>\13. 退出</p><p>conda deactivate</p><p><em><strong>*六、Spark-Standalone模式*</strong></em></p><p>\1. 在node2、node3上安装Python(Anaconda)</p><p>出现base表明安装完成</p><p>\2. 将node1上的profile和.&#x2F;bashrc分发给node2、node3</p><p>#分发.bashrc</p><p>scp <del>&#x2F;.bashrc root@node2:</del>&#x2F;</p><p>scp <del>&#x2F;.bashrc root@node3:</del>&#x2F;</p><p>#分发profile</p><p>scp &#x2F;etc&#x2F;profile&#x2F; root@node2:&#x2F;etc&#x2F;</p><p>scp &#x2F;etc&#x2F;profile&#x2F; root@node3:&#x2F;etc&#x2F;</p><p>\3. 创建虚拟环境pyspark基于python3.8</p><p> conda create -n pyspark python&#x3D;3.8</p><p>\4. 切换到虚拟环境</p><p>conda activate pyspark</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps6192.tmp.jpg" alt="img"> </p><p>\5. 在虚拟环境内安装包</p><p>pip install pyhive pyspark jieba -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple">https://pypi.tuna.tsinghua.edu.cn/simple</a> </p><p>\6. 修改配置文件</p><p>cd &#x2F;export&#x2F;server&#x2F;spark&#x2F;conf</p><p>-配置workers</p><p>mv workers.template workers</p><p>vim workers</p><p># 将里面的localhost删除, 追加 </p><p>node1 </p><p>node2 </p><p>node3 </p><p>-配置spark-env.sh</p><p>mv spark-env.sh.template spark-env.sh</p><p>vim spark-env.sh</p><p>在底部追加如下内容 </p><p>## 设置JAVA安装目录 JAVA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;jdk  </p><p>## HADOOP软件配置文件目录,读取HDFS上文件和运行YARN集群 HADOOP_CONF_DIR&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop&#x2F;etc&#x2F;hadoop YARN_CONF_DIR&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop&#x2F;etc&#x2F;hadoop  </p><p>## 指定spark老大Master的IP和提交任务的通信端口</p><p># 告知Spark的master运行在哪个机器上 export SPARK_MASTER_HOST&#x3D;node1 </p><p># 告知sparkmaster的通讯端口 export SPARK_MASTER_PORT&#x3D;7077</p><p> # 告知spark master的 webui端口 SPARK_MASTER_WEBUI_PORT&#x3D;8080  </p><p># worker cpu可用核数 SPARK_WORKER_CORES&#x3D;1 # worker可用内存 SPARK_WORKER_MEMORY&#x3D;1g </p><p># worker的工作通讯地址 SPARK_WORKER_PORT&#x3D;7078</p><p> # worker的 webui地址 SPARK_WORKER_WEBUI_PORT&#x3D;8081  </p><p>## 设置历史服务器# 配置的意思是  将spark程序运行的历史日志存到hdfs的&#x2F;sparklog文件夹中 SPARK_HISTORY_OPTS&#x3D;”Dspark.history.fs.logDirectory&#x3D;hdfs:&#x2F;&#x2F;node1:8020&#x2F;sparklog&#x2F; Dspark.history.fs.cleaner.enabled&#x3D;true”</p><p>\7. 在HDFS上创建程序运行历史记录存放的文件夹:</p><p>hadoop fs -mkdir &#x2F;sparklog </p><p>hadoop fs -chmod 777 &#x2F;sparklog</p><p>-配置spark-defaults.conf.template</p><p>mv spark-defaults.conf.template spark-defaults.conf </p><p>vim spark-defaults.conf </p><p># 修改内容, 追加如下内容</p><p># 开启spark的日期记录功能 spark.eventLog.enabled  true </p><p># 设置spark日志记录的路径 spark.eventLog.dir  hdfs:&#x2F;&#x2F;node1:8020&#x2F;sparklog&#x2F;  </p><p># 设置spark日志是否启动压缩 spark.eventLog.compress  true</p><p> -配置log4j.properties</p><p> mv log4j.properties.template log4j.properties</p><p> vim log4j.properties</p><p> <img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps6193.tmp.jpg" alt="img"></p><p>\8. 将node1的spark分发到node2、node3</p><p> cd &#x2F;export&#x2F;server&#x2F;</p><p> scp -r &#x2F;export&#x2F;server&#x2F;spark-3.2.0-bin-hadoop3.2&#x2F; node2:$PWD</p><p>scp -r &#x2F;export&#x2F;server&#x2F;spark-3.2.0-bin-hadoop3.2&#x2F; node3:$PWD</p><p>\9. 在node2和node3上做软连接</p><p>ln -s &#x2F;export&#x2F;server&#x2F;spark-3.2.0-bin-hadoop3.2 &#x2F;export&#x2F;server&#x2F;spark</p><p>\10. 重新加载环境变量</p><p>source &#x2F;etc&#x2F;profile</p><p>\11. 启动历史服务器</p><p>cd &#x2F;export&#x2F;server&#x2F;spark&#x2F;sbin</p><p>.&#x2F;start-history-server.sh</p><p>\12. 访问WebUI界面（<a href="http://node1:18080/%EF%BC%89">http://node1:18080/）</a></p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps6194.tmp.jpg" alt="img"> </p><p>\13. 启动Spark的Master和Worker</p><p># 启动全部master和worker sbin&#x2F;start-all.sh  </p><p># 或者可以一个个启动: </p><p># 启动当前机器的master </p><p>sbin&#x2F;start-master.sh </p><p># 启动当前机器的worker </p><p>sbin&#x2F;start-worker.sh  </p><p># 停止全部 </p><p>sbin&#x2F;stop-all.sh  </p><p># 停止当前机器的master </p><p>sbin&#x2F;stop-master.sh  </p><p># 停止当前机器的worker </p><p>sbin&#x2F;stop-worker.sh</p><p>\14. 访问WebUI界面（<a href="http://node1:8080/%EF%BC%89">http://node1:8080/）</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;*五、Spark-local模式*&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;\1. 上传并安装Anaconda3-2021.05-Linux-x86_64.sh文件&lt;/p&gt;
&lt;p&gt;cd &amp;#x2F;export&amp;#x2F;server&amp;#x2F;&lt;</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2022/05/17/Spark%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/2022/05/17/Spark%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/</id>
    <published>2022-05-17T01:24:19.879Z</published>
    <updated>2022-05-17T01:31:06.576Z</updated>
    
    <content type="html"><![CDATA[<p><em><strong>*一、配置基础环境*</strong></em> </p><p>#主机名 </p><p> cat &#x2F;etc&#x2F;hostname</p><p> # hosts映射</p><p> vim &#x2F;etc&#x2F;hosts</p><p> 127.0.0.1  localhost localhost.localdomain localhost4 localhost4.localdomain4</p><p> ::1     localhost localhost.localdomain localhost6 localhost6.localdomain6</p><p> 192.168.88.151 node1.itcast.cn node1</p><p> 192.168.88.152 node2.itcast.cn node2</p><p> 192.168.88.153 node3.itcast.cn node3</p><p><em><strong>*二、安装配置jdk*</strong></em></p><p>\1. 编译环境软件安装目录</p><p>mkdir -p &#x2F;export&#x2F;server</p><p>\2. 上传jdk-8u65-linux-x64.tar.gz到&#x2F;export&#x2F;server&#x2F;目录并解压</p><p> rz</p><p> tar -zxvf jdk-8u65-linux-x64.tar.gz</p><p>\3. 配置环境变量</p><p> vim &#x2F;etc&#x2F;profile</p><p>export JAVA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;jdk1.8.0_241</p><p>export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin</p><p>export CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;dt.jar:$JAVA_HOME&#x2F;lib&#x2F;tools.jar</p><p>\4. 重新加载环境变量文件</p><p> source &#x2F;etc&#x2F;profile</p><p>\5. 查看java版本号</p><p>Java -version</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps1443.tmp.jpg" alt="img"> </p><p>\6. 将java由node1分发到node2、node3</p><p>scp -r &#x2F;export&#x2F;server&#x2F;jdk1.8.0_241&#x2F; root@node2:&#x2F;export&#x2F;server</p><p>scp -r &#x2F;export&#x2F;server&#x2F;jdk1.8.0_241&#x2F; root@node3:&#x2F;export&#x2F;server</p><p>\7. 配置node2、node3的环境变量文件（方法如上）</p><p>\8. 在node1、node2、node3中创建软连接（三台都需要操作）</p><p> cd &#x2F;export&#x2F;server&#x2F;</p><p> ln -s jdk1.8.0_241&#x2F; jdk</p><p><em><strong>*三、Hadoop安装配置*</strong></em></p><p>\1. 上传hadoop-3.3.0-Centos7-64-with-snappy.tar.gz 到 &#x2F;export&#x2F;server 并解压文件</p><p>tar -zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz</p><p>\2. 修改配置文件</p><p> cd &#x2F;export&#x2F;server&#x2F;hadoop-3.3.0&#x2F;etc&#x2F;hadoop</p><p>- hadoop-env.sh</p><p>  #文件最后添加</p><p>  export JAVA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;jdk1.8.0_241</p><p>  export HDFS_NAMENODE_USER&#x3D;root</p><p>  export HDFS_DATANODE_USER&#x3D;root</p><p>  export HDFS_SECONDARYNAMENODE_USER&#x3D;root</p><p>  export YARN_RESOURCEMANAGER_USER&#x3D;root</p><p>  export YARN_NODEMANAGER_USER&#x3D;root </p><p>- core-site.xml</p>  <!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 -->  <property><p>​    <name>fs.defaultFS</name></p><p>​    <value>hdfs:&#x2F;&#x2F;node1:8020</value></p>  </property>    <!-- 设置Hadoop本地保存数据路径 -->  <property><p>​    <name>hadoop.tmp.dir</name></p><p>​    <value>&#x2F;export&#x2F;data&#x2F;hadoop-3.3.0</value></p>  </property>    <!-- 设置HDFS web UI用户身份 -->  <property><p>​    <name>hadoop.http.staticuser.user</name></p><p>​    <value>root</value></p>  </property>    <!-- 整合hive 用户代理设置 -->  <property><p>​    <name>hadoop.proxyuser.root.hosts</name></p><p>​    <value>*</value></p>  </property>    <property><p>​    <name>hadoop.proxyuser.root.groups</name></p><p>​    <value>*</value></p>  </property>    <!-- 文件系统垃圾桶保存时间 -->  <property><p>​    <name>fs.trash.interval</name></p><p>​    <value>1440</value></p>  </property>  <p>- hdfs-site.xml</p>  <!-- 设置SNN进程运行机器位置信息 -->  <property><p>​    <name>dfs.namenode.secondary.http-address</name></p><p>​    <value>node2:9868</value></p></property> <p>- mapred-site.xml</p>  <!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 -->  <property><p>   <name>mapreduce.framework.name</name></p><p>   <value>yarn</value></p>  </property>    <!-- MR程序历史服务地址 -->  <property><p>   <name>mapreduce.jobhistory.address</name></p><p>   <value>node1:10020</value></p>  </property>     <!-- MR程序历史服务器web端地址 -->  <property><p>   <name>mapreduce.jobhistory.webapp.address</name></p><p>   <value>node1:19888</value></p>  </property>    <property><p>   <name>yarn.app.mapreduce.am.env</name></p><p>   <value>HADOOP_MAPRED_HOME&#x3D;${HADOOP_HOME}</value></p>  </property>    <property><p>   <name>mapreduce.map.env</name></p><p>   <value>HADOOP_MAPRED_HOME&#x3D;${HADOOP_HOME}</value></p>  </property>    <property><p>   <name>mapreduce.reduce.env</name></p><p>   <value>HADOOP_MAPRED_HOME&#x3D;${HADOOP_HOME}</value></p></property> <p>- yarn-site.xml</p>  <!-- 设置YARN集群主角色运行机器位置 -->  <property><pre><code>  &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;    &lt;value&gt;node1&lt;/value&gt;</code></pre>  </property>    <property><p>​    <name>yarn.nodemanager.aux-services</name></p><p>​    <value>mapreduce_shuffle</value></p>  </property>    <!-- 是否将对容器实施物理内存限制 -->  <property><p>​    <name>yarn.nodemanager.pmem-check-enabled</name></p><p>​    <value>false</value></p>  </property>    <!-- 是否将对容器实施虚拟内存限制。 -->  <property><p>​    <name>yarn.nodemanager.vmem-check-enabled</name></p><p>​    <value>false</value></p>  </property>    <!-- 开启日志聚集 -->  <property><p>   <name>yarn.log-aggregation-enable</name></p><p>   <value>true</value></p>  </property>    <!-- 设置yarn历史服务器地址 -->  <property><p>​    <name>yarn.log.server.url</name></p><p>​    <value><a href="http://node1:19888/jobhistory/logs">http://node1:19888/jobhistory/logs</a></value></p>  </property>    <!-- 历史日志保存的时间 7天 -->  <property><p>   <name>yarn.log-aggregation.retain-seconds</name></p><p>   <value>604800</value></p></property> <p> - workers</p><p>  node1.itcast.cn</p><p>  node2.itcast.cn</p><p>  node3.itcast.cn</p><p>\3. 将node1的hadoop-3.3.0分发到node2、node3</p><p> cd &#x2F;export&#x2F;server</p><p> scp -r &#x2F;export&#x2F;server&#x2F;hadoop-3.3.0 root@node2:$PWD</p><p>scp -r &#x2F;export&#x2F;server&#x2F;hadoop-3.3.0 root@node3:$PWD</p><p>\4. 将hadoop添加到环境变量</p><p> vim &#x2F;etc&#x2F;profile</p><p>export HADOOP_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;hadoop-3.3.0</p><p>export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;bin:$HADOOP_HOME&#x2F;sbin</p><p>\5. 重新加载环境变量文件</p><p> source &#x2F;etc&#x2F;profile</p><p>\6. Hadoop集群启动</p><p>（1）格式化namenode（只有首次启动需要格式化）</p><p>hdfs namenode -format</p><p>（2）脚本一键启动</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps1444.tmp.jpg" alt="img"> </p><p>\7. WEB界面</p><p>（1）HDFS集群：<a href="http://node1:9870/">http://node1:9870/</a></p><p>（2）YARN集群：<a href="http://node1:8088/">http://node1:8088/</a></p><p><em><strong>*四、zookeeper安装配置*</strong></em></p><p>\1. 上传zookeeper-3.4.10.tar.gz到&#x2F;export&#x2F;server&#x2F;目录下并解压文件</p><p> cd &#x2F;export&#x2F;server&#x2F;</p><p> Tar -zxvf zookeeper-3.4.10.tar.gz</p><p>\2. 创建软连接</p><p> cd &#x2F;export&#x2F;server&#x2F;</p><p> ln -s zookeeper-3.4.10&#x2F; zookeeper</p><p>\3. 修改配置文件</p><p> cd &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;conf&#x2F;</p><p>(1) cp zoo_sample.cfg zoo.cfg</p><p>vim zoo.cfg</p><p>将zoo.cfg修改为以下内容</p><p>#Zookeeper的数据存放目录</p><p>dataDir&#x3D;&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas</p><p># 保留多少个快照</p><p>autopurge.snapRetainCount&#x3D;3</p><p># 日志多少小时清理一次</p><p>autopurge.purgeInterval&#x3D;1</p><p># 集群中服务器地址</p><p>server.1&#x3D;node1:2888:3888</p><p>server.2&#x3D;node2:2888:3888</p><p>server.3&#x3D;node3:2888:3888</p><p>(2) 在node1主机的&#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;这个路径下创建一个文件，文件名为myid ,文件内容为1</p><p>echo 1 &gt; &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;myid</p><p>(3) 将node1中&#x2F;export&#x2F;server&#x2F;zookeeper-3.4.10分发给node2、node3</p><p>scp -r &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.10&#x2F; slave1:$PWD </p><p>scp -r &#x2F;export&#x2F;server&#x2F;zookeeper-3.4.10&#x2F; slave2:$PWD</p><p>(4) 在node2和node3上创建软连接</p><p>​    ln -s zookeeper-3.4.10&#x2F; zookeeper</p><p>(5) 分别在node2、node3上修改myid的值为2，3</p><p>cd &#x2F;export&#x2F;server&#x2F;</p><p>echo 2 &gt; &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;myid</p><p>echo 3 &gt; &#x2F;export&#x2F;server&#x2F;zookeeper&#x2F;zkdatas&#x2F;myid</p><p>(6) 配置zookeeper的环境变量（三台都需要配置）</p><p>vim &#x2F;etc&#x2F;profile</p><p>export ZOOKEEPER_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;zookeeper</p><p>export PATH&#x3D;$PATH:$ZOOKEEPER_HOME&#x2F;bin</p><p>(7) 重新加载环境变量</p><p>source &#x2F;etc&#x2F;profile </p><p>(8) 三台机器开启zookeeper</p><p>cd &#x2F;export&#x2F;server&#x2F;zookerper-3.4.10&#x2F;bin</p><p>zkServer.sh start</p><p>(9) 结果显示</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps1454.tmp.jpg" alt="img"><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps1455.tmp.jpg" alt="img"> </p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps1456.tmp.jpg" alt="img"> </p><p>(10) 查看zookeeper状态</p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps1457.tmp.jpg" alt="img"> </p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps1458.tmp.jpg" alt="img"> </p><p><img src="file:///C:\Users\Administrator\AppData\Local\Temp\ksohtml\wps1459.tmp.jpg" alt="img"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;*一、配置基础环境*&lt;/strong&gt;&lt;/em&gt; &lt;/p&gt;
&lt;p&gt;#主机名 &lt;/p&gt;
&lt;p&gt; cat &amp;#x2F;etc&amp;#x2F;hostname&lt;/p&gt;
&lt;p&gt; # hosts映射&lt;/p&gt;
&lt;p&gt; vim &amp;#x2F;etc&amp;#x2F;hosts</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/2022/05/15/hello-world/"/>
    <id>http://example.com/2022/05/15/hello-world/</id>
    <published>2022-05-15T12:35:33.382Z</published>
    <updated>2022-05-15T12:35:33.382Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
